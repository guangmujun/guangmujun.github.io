(window.webpackJsonp=window.webpackJsonp||[]).push([[101],{677:function(a,t,r){"use strict";r.r(t);var _=r(7),n=Object(_.a)({},(function(){var a=this,t=a.$createElement,r=a._self._c||t;return r("ContentSlotsDistributor",{attrs:{"slot-key":a.$parent.slotKey}},[r("h1",{attrs:{id:"整体流程"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#整体流程"}},[a._v("#")]),a._v(" 整体流程")]),a._v(" "),r("p",[a._v("数据探索，Exploratory Data Analysis， EDA")]),a._v(" "),r("ol",[r("li",[a._v("统计层面分析")]),a._v(" "),r("li",[a._v("缺失值处理")]),a._v(" "),r("li",[a._v("异常值处理")]),a._v(" "),r("li",[a._v("Label分析")]),a._v(" "),r("li",[a._v("特征分析")])]),a._v(" "),r("h1",{attrs:{id:"详细步骤"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#详细步骤"}},[a._v("#")]),a._v(" 详细步骤")]),a._v(" "),r("h2",{attrs:{id:"_1-载入库"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#_1-载入库"}},[a._v("#")]),a._v(" 1 载入库")]),a._v(" "),r("ol",[r("li",[a._v("warnings包，忽视警告")]),a._v(" "),r("li",[a._v("使用missingno包进行缺失值可视化处理，需安装"),r("code",[a._v("pip install missingno")])])]),a._v(" "),r("p",[a._v("​"),r("br"),a._v("\nimport warnings\nwarnings.filterwarnings('ignore')\nimport missingno as msno  # 缺失值可视化处理")]),a._v(" "),r("h2",{attrs:{id:"_2-载入数据"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#_2-载入数据"}},[a._v("#")]),a._v(" 2 载入数据")]),a._v(" "),r("ol",[r("li",[a._v("数据中使用空格作为各列数据间的分隔符，载入数据时加上"),r("code",[a._v("sep")]),a._v("参数")]),a._v(" "),r("li",[a._v("pandas的append用法，可将数据拼接到一起")])]),a._v(" "),r("p",[a._v("​"),r("br"),a._v("\nTrain_data = pd.read_csv('used_car_train_20200313.csv', sep=' ')")]),a._v(" "),r("div",{staticClass:"language- extra-class"},[r("pre",[r("code",[a._v("Train_data.head().append(Train_data.tail())\n")])])]),r("h2",{attrs:{id:"_3-总览数据"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#_3-总览数据"}},[a._v("#")]),a._v(" 3 总览数据")]),a._v(" "),r("ol",[r("li",[a._v("describe()函数直观的看到部分变量的样本值有缺失")]),a._v(" "),r("li",[a._v("通过info()函数了解数据每列的type，发现"),r("code",[a._v("notRepairedDamage")]),a._v("特征的类型为"),r("code",[a._v("object")]),a._v("，此变量表示汽车有尚未修复的损坏，取值为0或1，但是在数据集中有部分样的值为"),r("code",[a._v("-")])])]),a._v(" "),r("p",[a._v("​"),r("br"),a._v("\nTrain_data.describe()")]),a._v(" "),r("div",{staticClass:"language- extra-class"},[r("pre",[r("code",[a._v("Train_data.info()\n")])])]),r("h2",{attrs:{id:"_4-判断数据缺失值"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#_4-判断数据缺失值"}},[a._v("#")]),a._v(" 4 判断数据缺失值")]),a._v(" "),r("ol",[r("li",[a._v("通过"),r("code",[a._v("isnull().sum()")]),a._v("查看每列nan的情况")]),a._v(" "),r("li",[a._v("对于nan的处理")])]),a._v(" "),r("div",{staticClass:"language- extra-class"},[r("pre",[r("code",[a._v("* 个数较少，使用填充，如果使用lgb等树模型可以直接空缺，让树自己去优化\n* 个数较多，考虑删除这个特征\n")])])]),r("p",[a._v("​"),r("br"),a._v("\n​"),r("br"),a._v("\nTrain_data.isnull().sum()")]),a._v(" "),r("div",{staticClass:"language- extra-class"},[r("pre",[r("code",[a._v("Test_data.isnull().sum()\n")])])]),r("ol",{attrs:{start:"3"}},[r("li",[a._v("查看训练集中有nan值的特征的nan值分布情况")])]),a._v(" "),r("p",[a._v("​"),r("br"),a._v("\nmissing = Train_data.isnull().sum()\nmissing = missing[missing > 0]\nmissing.sort_values(inplace=True)  # inpalce表示是否用排序后的数据集替换原数据\nmissing.plot.bar()")]),a._v(" "),r("p",[r("img",{attrs:{src:"https://img-blog.csdnimg.cn/20200324153649638.png",alt:""}})]),a._v(" "),r("ol",{attrs:{start:"4"}},[r("li",[a._v("使用missingno库 ，可视化缺省值")])]),a._v(" "),r("p",[a._v("​"),r("br"),a._v("\nimport missingno as msno\nmsno.matrix(Train_data.sample(250))")]),a._v(" "),r("p",[r("img",{attrs:{src:"https://img-blog.csdnimg.cn/20200324154018876.png",alt:""}})]),a._v(" "),r("p",[a._v("上图中，左边的纵轴从上至下表示第1-250个样本，当一列中出现白色横线时，表示这个样本的这个特征的值有缺失，然后在右侧的纵轴上便会有一个波动，波动越大，说明此条样本缺失的特征越多。在右侧的纵轴上会标出完整性最大的点和最小的点，上图中的28应该表示第28个样本的完整性最小，即缺失的特征最多。")]),a._v(" "),r("p",[a._v("​"),r("br"),a._v("\nmsno.bar(Train_data.sample(1000))")]),a._v(" "),r("p",[r("img",{attrs:{src:"https://img-blog.csdnimg.cn/20200324154448433.png",alt:""}})]),a._v(" "),r("p",[r("code",[a._v("msno.bar")]),a._v(" 简单的展示数据的完整度，右侧纵轴表示第0-1000个样本，左侧纵轴表示样本数据的完整度。")]),a._v(" "),r("h2",{attrs:{id:"_5-判断数据异常值"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#_5-判断数据异常值"}},[a._v("#")]),a._v(" 5 判断数据异常值")]),a._v(" "),r("ol",[r("li",[a._v("处理notRepairedDamage：")])]),a._v(" "),r("p",[a._v("通过显示其中不同的值来观察数据")]),a._v(" "),r("p",[a._v("​"),r("br"),a._v("\nTrain_data['notRepairedDamage'].value_counts()")]),a._v(" "),r("p",[a._v("发现"),r("code",[a._v("-")]),a._v("为缺失值，先换成nan处理")]),a._v(" "),r("p",[a._v("​"),r("br"),a._v("\nTrain_data['notRepairedDamage'].replace('-', np.nan, inplace=True)")]),a._v(" "),r("p",[r("code",[a._v("value_counts()")]),a._v("函数不会统计nan的数量，使用 "),r("code",[a._v("isnull().sum()")]),a._v("函数来查看")]),a._v(" "),r("p",[a._v("​"),r("br"),a._v("\nTrain_data.isnull().sum()")]),a._v(" "),r("p",[a._v("对测试集执行相同的操作")]),a._v(" "),r("ol",{attrs:{start:"2"}},[r("li",[a._v("删除训练集和测试集中严重倾斜的特征")])]),a._v(" "),r("p",[a._v("使用"),r("code",[a._v("value_counts()")]),a._v("函数统计每个特征的取值分布情况，如：【参考 7 查看数据特征 第2点】")]),a._v(" "),r("p",[a._v("​"),r("br"),a._v("\nTrain_data['seller'].value_counts()")]),a._v(" "),r("p",[a._v("输出：")]),a._v(" "),r("p",[a._v("​"),r("br"),a._v("\n0    149999\n1         1\nName: seller, dtype: int64")]),a._v(" "),r("p",[a._v("删除特征seller, offerType")]),a._v(" "),r("p",[a._v("​"),r("br"),a._v("\ndel Train_data['seller']\ndel Train_data['offerType']\ndel Test_data['seller']\ndel Test_data['offerType']")]),a._v(" "),r("h2",{attrs:{id:"_6-了解预测值分布"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#_6-了解预测值分布"}},[a._v("#")]),a._v(" 6 了解预测值分布")]),a._v(" "),r("ol",[r("li",[a._v("查看预测值基本信息")])]),a._v(" "),r("p",[a._v("​"),r("br"),a._v("\nTrain_data['price']\nTrain_data['price'].value_counts()")]),a._v(" "),r("ol",{attrs:{start:"2"}},[r("li",[a._v("查看预测值总体分布情况")])]),a._v(" "),r("p",[a._v("​"),r("br"),a._v("\nimport scipy.stats as st")]),a._v(" "),r("div",{staticClass:"language- extra-class"},[r("pre",[r("code",[a._v("y = Train_data['price']\nplt.figure(1);plt.title('Johnson SU')\nsns.distplot(y, kde=False, fit=st.johnsonsu)  # distplot绘制观测值的单变量分布。\nplt.figure(2);plt.title('Normal')\nsns.distplot(y, kde=False, fit=st.norm)  # kde参数：是否绘制高斯核密度估计。\nplt.figure(3);plt.title('Log Normal')\nsns.distplot(y, kde=False, fit=st.lognorm)\n")])])]),r("p",[r("img",{attrs:{src:"https://img-blog.csdnimg.cn/20200324162249704.png",alt:""}}),a._v(" ![](https://img-\nblog.csdnimg.cn/20200324162415246.png) ![](https://img-\nblog.csdnimg.cn/20200324162511779.png)")]),a._v(" "),r("p",[a._v("从上图可知，横轴表示样本的各个价格，纵轴表示这一价格对应的样本数量与样本总数的比值。第一个图中的曲线拟合情况最好，所以预测值服从无界约翰逊分布，而不是服从正太分布。关于"),r("a",{attrs:{href:"http://www.nematrian.com/JohnsonSUDistribution",target:"_blank",rel:"noopener noreferrer"}},[a._v("无界约翰逊分布"),r("OutboundLink")],1),a._v("（JohnsonSUDistribution）一些信息。")]),a._v(" "),r("ol",{attrs:{start:"3"}},[r("li",[a._v("查看预测值频数情况")])]),a._v(" "),r("p",[a._v("​"),r("br"),a._v("\nplt.hist(Train_data['price'], orientation='vertical', histtype='bar', color='red')\nplt.show()")]),a._v(" "),r("p",[r("img",{attrs:{src:"https://img-blog.csdnimg.cn/20200324170456713.png",alt:""}})]),a._v(" "),r("p",[a._v("从上图可知：大于20000的值比较少，可以把这些当作异常值直接用填充，或者删除掉。")]),a._v(" "),r("p",[a._v("​"),r("br"),a._v("\nplt.hist(np.log(Train_data['price']), orientation='vertical', histtype='bar', color='red')\nplt.show()")]),a._v(" "),r("p",[r("img",{attrs:{src:"https://img-blog.csdnimg.cn/20200324170520390.png",alt:""}})]),a._v(" "),r("p",[a._v("从上图可知：log变换预测值之后的分布较均匀，可以用log变换进行预测（ "),r("strong",[a._v("预测问题常用trick")]),a._v(" ）")]),a._v(" "),r("ol",{attrs:{start:"4"}},[r("li",[a._v("查看偏度（Skewness）和峰度（Kurtosis）")])]),a._v(" "),r("p",[r("strong",[a._v("预测值的偏度和峰度：")])]),a._v(" "),r("p",[a._v("​"),r("br"),a._v("\nsns.distplot(Train_data['price']);\nprint('Skewness: %f' % Train_data['price'].skew())\nprint('Kurtosis: %f' % Train_data['price'].kurt())\nTrain_data.skew(), Train_data.kurt()")]),a._v(" "),r("p",[r("img",{attrs:{src:"https://img-blog.csdnimg.cn/20200324164715427.png",alt:""}})]),a._v(" "),r("p",[a._v("从上图可知：预测值的分布，呈现出右偏，尖顶峰 "),r("strong",[a._v("知识补充：")]),a._v("\n详细见"),r("a",{attrs:{href:"https://www.cnblogs.com/wyy1480/p/10474046.html",target:"_blank",rel:"noopener noreferrer"}},[a._v("参考网站"),r("OutboundLink")],1),a._v(" 1.\n用skewness和kurtosis来看数据的分布形态，一般会和正态分布比较，所以把正态分布的skewness和kurtosis都看作0. 2.\n偏度：描述的是某总体取值分布的对称性 （1）Skewness = 0 ，分布形态与正态分布偏度相同。 （2）Skewness > 0\n，正偏差数值较大，为正偏或右偏。长尾巴拖在右边，数据右端有较多的极端值。 （3）Skewness < 0\n，负偏差数值较大，为负偏或左偏。长尾巴拖在左边，数据左端有较多的极端值。 （4）数值的绝对值越大，表明数据分布越不对称，偏斜程度大。 3.\n峰度：是数据分布顶的尖锐程度 （1）Kurtosis=0 与正态分布的陡缓程度相同。 （2）Kurtosis>0 比正态分布的高峰更加陡峭——尖顶峰\n（3）Kurtosis<0 比正态分布的高峰来得平台——平顶峰 "),r("strong",[a._v("训练集的偏度和峰度：")])]),a._v(" "),r("p",[a._v("​"),r("br"),a._v("\nsns.distplot(Train_data.skew(), color='blue', axlabel='Skewness')\nsns.distplot(Train_data.kurt(), color='orange', axlabel='Kurtness')")]),a._v(" "),r("p",[r("img",{attrs:{src:"https://img-blog.csdnimg.cn/20200324165143156.png",alt:""}}),a._v(" ![](https://img-\nblog.csdnimg.cn/20200324165154977.png)")]),a._v(" "),r("p",[a._v("上图中，以偏度图为例，横轴表示数据集中所有特征分布的偏度值，纵轴表示拥有此分布特征分布的偏度值的特征数与总特征数的比值。")]),a._v(" "),r("h2",{attrs:{id:"_7-查看数据特征"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#_7-查看数据特征"}},[a._v("#")]),a._v(" 7 查看数据特征")]),a._v(" "),r("ol",[r("li",[a._v("特征分类")])]),a._v(" "),r("p",[a._v("​"),r("br"),a._v("\nY_train = Train_data['price']\nnumeric_features = ['power', 'kilometer', 'v_0', 'v_1', 'v_2', 'v_3', 'v_4', 'v_5', 'v_6', 'v_7', 'v_8', 'v_9', 'v_10', 'v_11', 'v_12', 'v_13','v_14' ]\ncategorical_features = ['name', 'model', 'brand', 'bodyType', 'fuelType', 'gearbox', 'notRepairedDamage', 'regionCode']")]),a._v(" "),r("ol",{attrs:{start:"2"}},[r("li",[a._v("查看各个特征的unique分布（特征的各个值出现的次数）")])]),a._v(" "),r("p",[a._v("​"),r("br"),a._v("\nfor cat_fea in categorical_features:\nprint(cat_fea + '的特征分布如下：')\nprint('{}特征有{}个不同的值：'.format(cat_fea, Train_data[cat_fea].nunique()))\nprint(Train_data[cat_fea].value_counts())")]),a._v(" "),r("p",[a._v("分别查看训练集和测试集")]),a._v(" "),r("h3",{attrs:{id:"数字特征-连续"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#数字特征-连续"}},[a._v("#")]),a._v(" 数字特征（连续）")]),a._v(" "),r("ol",[r("li",[a._v("数字特征总览")])]),a._v(" "),r("p",[a._v("​"),r("br"),a._v("\nnumeric_features.append('price')\nnumeric_features")]),a._v(" "),r("ol",{attrs:{start:"2"}},[r("li",[a._v("相关性分析")])]),a._v(" "),r("p",[a._v("计算相关系数")]),a._v(" "),r("p",[a._v("​"),r("br"),a._v("\nprice_numeric = Train_data[numeric_features]\ncorrelation = price_numeric.corr()  # 求相关系数\nprint(correlation['price'].sort_values(ascending = False), '\\n')   # 降序")]),a._v(" "),r("p",[a._v("绘制特征的相关系数矩阵图")]),a._v(" "),r("p",[a._v("​"),r("br"),a._v("\nf, ax = plt.subplots(figsize=(7,7))\nplt.title('Correlation of Numeric Features with Price', y=1, size=16)\nsns.heatmap(correlation, square=True, vmax=0.8)  # square：单元格为方格 vmax:右侧色条可见的最大数值")]),a._v(" "),r("p",[r("img",{attrs:{src:"https://img-blog.csdnimg.cn/20200324171618437.png",alt:""}})]),a._v(" "),r("p",[a._v("从上图可知：方格颜色最浅或者最深，则此方格对应的两个特征之间相关性越大。")]),a._v(" "),r("ol",{attrs:{start:"3"}},[r("li",[a._v("查看特征的偏度和峰值")])]),a._v(" "),r("p",[a._v("​"),r("br"),a._v("\ndel price_numeric['price']")]),a._v(" "),r("div",{staticClass:"language- extra-class"},[r("pre",[r("code",[a._v("for col in numeric_features:\n    print('{:15}'.format(col),  # {}中的数字表示空格和精度\n         'Skewness:{:05.2f}'.format(Train_data[col].skew()),\n         ' ',\n         'Kurtosis:{:06.2f}'.format(Train_data[col].kurt())\\\n         )\n")])])]),r("ol",{attrs:{start:"4"}},[r("li",[a._v("每个数字特征分布")])]),a._v(" "),r("p",[a._v("​"),r("br"),a._v('\nf = pd.melt(Train_data, value_vars=numeric_features)  # 将DataFrame从宽格式转为长格式\ng = sns.FacetGrid(f, col="variable",  col_wrap=2, sharex=False, sharey=False)\ng = g.map(sns.distplot, "value")')]),a._v(" "),r("p",[r("img",{attrs:{src:"https://img-blog.csdnimg.cn/20200324172207646.png",alt:""}})]),a._v(" "),r("p",[a._v("这里的图的含义，和前述都差不多，横轴表示这个特征所有的取值，纵轴表示特征值等这个取值的样本数与总样本数的比值。")]),a._v(" "),r("ol",{attrs:{start:"5"}},[r("li",[a._v("数字特征之间的关系分析")])]),a._v(" "),r("p",[a._v("​"),r("br"),a._v("\nsns.set()\ncolumns = ['price', 'v_12', 'v_8' , 'v_0', 'power', 'v_5',  'v_2', 'v_6', 'v_1', 'v_14']  # 根据前述计算的相关系数，挑选相关性较大的变量\nsns.pairplot(Train_data[columns], size=2, kind='scatter', diag_kind='kde')\nplt.show()")]),a._v(" "),r("p",[r("img",{attrs:{src:"https://img-blog.csdnimg.cn/20200324172522265.png",alt:""}})]),a._v(" "),r("p",[a._v("从上图可知：当两个特征之间存在较强的关系，会出现共线性，需要考虑去除共线性。")]),a._v(" "),r("ol",{attrs:{start:"5"}},[r("li",[a._v("多变量互相回归关系可视化")])]),a._v(" "),r("p",[a._v("可以根据前述的相关系数或者特征关系矩阵，来挑选部分特征再次进行回归分析。")]),a._v(" "),r("p",[a._v("​"),r("br"),a._v("\nfig, ((ax1, ax2), (ax3, ax4), (ax5, ax6), (ax7, ax8), (ax9, ax10)) = plt.subplots(nrows=5, ncols=2, figsize=(24, 20))\n# ['v_12', 'v_8' , 'v_0', 'power', 'v_5',  'v_2', 'v_6', 'v_1', 'v_14', 'v_13']\nv_12_scatter_plot = pd.concat([Y_train,Train_data['v_12']],axis = 1)\nsns.regplot(x='v_12',y = 'price', data = v_12_scatter_plot,scatter= True, fit_reg=True, ax=ax1)")]),a._v(" "),r("div",{staticClass:"language- extra-class"},[r("pre",[r("code",[a._v("v_8_scatter_plot = pd.concat([Y_train,Train_data['v_8']],axis = 1)\nsns.regplot(x='v_8',y = 'price',data = v_8_scatter_plot,scatter= True, fit_reg=True, ax=ax2)\n\nv_0_scatter_plot = pd.concat([Y_train,Train_data['v_0']],axis = 1)\nsns.regplot(x='v_0',y = 'price',data = v_0_scatter_plot,scatter= True, fit_reg=True, ax=ax3)\n\npower_scatter_plot = pd.concat([Y_train,Train_data['power']],axis = 1)\nsns.regplot(x='power',y = 'price',data = power_scatter_plot,scatter= True, fit_reg=True, ax=ax4)\n\nv_5_scatter_plot = pd.concat([Y_train,Train_data['v_5']],axis = 1)\nsns.regplot(x='v_5',y = 'price',data = v_5_scatter_plot,scatter= True, fit_reg=True, ax=ax5)\n\nv_2_scatter_plot = pd.concat([Y_train,Train_data['v_2']],axis = 1)\nsns.regplot(x='v_2',y = 'price',data = v_2_scatter_plot,scatter= True, fit_reg=True, ax=ax6)\n\nv_6_scatter_plot = pd.concat([Y_train,Train_data['v_6']],axis = 1)\nsns.regplot(x='v_6',y = 'price',data = v_6_scatter_plot,scatter= True, fit_reg=True, ax=ax7)\n\nv_1_scatter_plot = pd.concat([Y_train,Train_data['v_1']],axis = 1)\nsns.regplot(x='v_1',y = 'price',data = v_1_scatter_plot,scatter= True, fit_reg=True, ax=ax8)\n\nv_14_scatter_plot = pd.concat([Y_train,Train_data['v_14']],axis = 1)\nsns.regplot(x='v_14',y = 'price',data = v_14_scatter_plot,scatter= True, fit_reg=True, ax=ax9)\n\nv_13_scatter_plot = pd.concat([Y_train,Train_data['v_13']],axis = 1)\nsns.regplot(x='v_13',y = 'price',data = v_13_scatter_plot,scatter= True, fit_reg=True, ax=ax10)\n")])])]),r("p",[r("img",{attrs:{src:"https://img-blog.csdnimg.cn/20200324173126417.png",alt:""}})]),a._v(" "),r("p",[a._v("从上图可知：部分解释变量与被解释变量之间没有太大关系，可以考虑删除。")]),a._v(" "),r("h3",{attrs:{id:"类别特征-离散"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#类别特征-离散"}},[a._v("#")]),a._v(" 类别特征（离散）")]),a._v(" "),r("ol",[r("li",[a._v("查看类别特征的unique分布")])]),a._v(" "),r("p",[a._v("​"),r("br"),a._v("\nfor fea in categorical_features:\nprint(Train_data[fea].nunique())")]),a._v(" "),r("div",{staticClass:"language- extra-class"},[r("pre",[r("code",[a._v("categorical_features\n")])])]),r("ol",{attrs:{start:"2"}},[r("li",[a._v("箱型图可视化特征")])]),a._v(" "),r("p",[a._v("​"),r("br"),a._v("\n# 因为 name和 regionCode的类别太多，这里我们把类别不是特别多的几个特征画一下\ncategorical_features = ['model',\n'brand',\n'bodyType',\n'fuelType',\n'gearbox',\n'notRepairedDamage']")]),a._v(" "),r("div",{staticClass:"language- extra-class"},[r("pre",[r("code",[a._v("for c in categorical_features:\n    Train_data[c] = Train_data[c].astype('category')\n    if Train_data[c].isnull().any():  # 发现空值时，添加MISSING类，并且用”MISSING“来作为nan填充\n        Train_data[c] = Train_data[c].cat.add_categories(['MISSING'])\n        Train_data[c] = Train_data[c].fillna('MISSING')\n\ndef boxplot(x,y,**kwargs):\n    sns.boxplot(x=x, y=y)\n    x = plt.xticks(rotation=90)\n\nf = pd.melt(Train_data, id_vars=['price'], value_vars = categorical_features)\ng = sns.FacetGrid(f, col='variable', col_wrap=2, sharex=False, sharey=False, size=5)\ng = g.map(boxplot, 'value', 'price')\n")])])]),r("p",[r("img",{attrs:{src:"https://img-blog.csdnimg.cn/20200324174004196.png",alt:""}})]),a._v(" "),r("p",[a._v("所以，由上图可知，横轴中会出现MISSING这一类。")]),a._v(" "),r("ol",{attrs:{start:"3"}},[r("li",[a._v("类别特征的小提琴图可视化")])]),a._v(" "),r("p",[a._v("​"),r("br"),a._v("\ncatg_list = categorical_features\ntarget = 'price'\nfor catg in catg_list:\nsns.violinplot(x=catg,y=target, data=Train_data)\nplt.show()")]),a._v(" "),r("p",[r("img",{attrs:{src:"https://img-blog.csdnimg.cn/20200324174420383.png",alt:""}})]),a._v(" "),r("p",[a._v("可以看到各个特征的分布情况。")]),a._v(" "),r("ol",{attrs:{start:"4"}},[r("li",[a._v("类别特征的柱形图可视化")])]),a._v(" "),r("p",[a._v("​"),r("br"),a._v("\ncategorical_features = ['model',\n'brand',\n'bodyType',\n'fuelType',\n'gearbox',\n'notRepairedDamage']")]),a._v(" "),r("p",[a._v("​"),r("br"),a._v("\n​"),r("br"),a._v("\ndef bar_plot(x, y, **kwargs):\nsns.barplot(x=x, y=y)\nx = plt.xticks(rotation=90)")]),a._v(" "),r("div",{staticClass:"language- extra-class"},[r("pre",[r("code",[a._v("f = pd.melt(Train_data, id_vars=['price'], value_vars=categorical_features)\ng = sns.FacetGrid(f, col='variable', col_wrap=2, sharex=False, sharey=False, size=5)\ng = g.map(bar_plot, 'value', 'price')\n")])])]),r("p",[r("img",{attrs:{src:"https://img-blog.csdnimg.cn/20200324175036182.png",alt:""}})]),a._v(" "),r("p",[r("strong",[a._v("研究预测值与各个类别特征的关系，给出某个特征的每一个类别取值对应的预测值的平均数，以及”置信区间“（黑色的竖线）。")])]),a._v(" "),r("ol",{attrs:{start:"5"}},[r("li",[a._v("类别特征的每个类别频数可视化")])]),a._v(" "),r("p",[a._v("​"),r("br"),a._v("\ndef count_plot(x, **kwargs):\nsns.countplot(x=x)\nx = plt.xticks(rotation=90)")]),a._v(" "),r("div",{staticClass:"language- extra-class"},[r("pre",[r("code",[a._v("f = pd.melt(Train_data, value_vars=categorical_features)\ng = sns.FacetGrid(f, col='variable', col_wrap=2, sharex=False, sharey=False, size=5)\ng = g.map(count_plot, 'value')\n")])])]),r("p",[r("img",{attrs:{src:"https://img-blog.csdnimg.cn/20200324175055262.png",alt:""}})]),a._v(" "),r("p",[a._v("某个特征的每一个类别出现的频数。")]),a._v(" "),r("h2",{attrs:{id:"_8-生成数据报告"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#_8-生成数据报告"}},[a._v("#")]),a._v(" 8 生成数据报告")]),a._v(" "),r("p",[a._v("需要安装"),r("code",[a._v("pandas_profiling")]),a._v("库，可能出现安装失败的情况。有很多种解决办法，详见[官网](https://pypi.org/project/pandas-\nprofiling/)。 我是用"),r("code",[a._v("pip")]),a._v("安装失败，用"),r("code",[a._v("conda install -c conda-forge pandas-profiling")]),a._v("\n就可以了。")]),a._v(" "),r("p",[a._v("​"),r("br"),a._v("\nimport pandas_profiling")]),a._v(" "),r("div",{staticClass:"language- extra-class"},[r("pre",[r("code",[a._v("pfr = pandas_profiling.ProfileReport(Train_data)\npfr.to_file('./report.html')\n")])])]),r("p",[a._v("导出的效果不错！")])])}),[],!1,null,null,null);t.default=n.exports}}]);